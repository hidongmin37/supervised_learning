{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 부스팅 기법\n",
    "##### ada부스팅은 과적합을 줄일 수 있음(에러값들 모아두는 함수구하는 함수 손실함수라함)\n",
    "##### \n",
    "\n",
    "##### 그래디언(기울기)부스팅은 에러값들 다시 조정하면서 기울기값을 계속 줄여줌\n",
    "##### class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "###### subsample은 0과 1사이의 값으로 해야 작으므로 그사이값으로 지정해줘야함\n",
    "\n",
    "\n",
    "\n",
    "###### XG부스팅은 시간도 빨라지고, 예측도 좋아짐 그래디언 부스팅과 차이점은 크게 크게 나누고, 정규화까지 시켜주는 차이점이 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.각각의 함수를 만들어 전처리와 변수저장을 다 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df): # 인덱스값을 제거해서 전처리하는 과정\n",
    "    feature_dup_df=pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),columns=['dup_cnt'])\n",
    "    feature_dup_df= feature_dup_df.reset_index()\n",
    "    new_feature_name_df=pd.merge(old_feature_name_df.reset_index(),feature_dup_df,how='outer')\n",
    "    new_feature_name_df['column_name']=new_feature_name_df[['column_name','dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1])\n",
    "                                                                                            if x[1]>0 else x[0], axis=1)\n",
    "    new_feature_name_df=new_feature_name_df.drop(['index'],axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "def get_human_dataset( ): # 파일들 변수에 저장해주는 함수\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./drive/MyDrive/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name']) #CSV불러오는 \n",
    "    \n",
    "    # 중복된 feature명을 새롭게 수정하는 get_new_feature_name_df()를 이용하여 새로운 feature명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./drive/MyDrive/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./drive/MyDrive/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./drive/MyDrive/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./drive/MyDrive/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "import get_human_dataset_copy as gh #모듈 써준 거\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.함수 불러와서 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test =gh.get_human_dataset() #함수 불러와서 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time() #시간 작성 \n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0) #gb부스팅 쓰기 \n",
    "gb_clf.fit(X_train,y_train) #gb부스팅 훈련\n",
    "gb_pred =gb_clf.predict(X_test) #예상값 가져오기\n",
    "gb_accuracy = accuracy_score(y_test,gb_pred) #정확도 측정\n",
    "\n",
    "print('GBM 정확도 : {0:.4f}'.format(gb_accuracy))\n",
    "print('GBM 수행시간:{0:.1f}초'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 그리드서치CV 를 통해서 하이퍼 파라미터에서 최적화를 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gb_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\boosting.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=2'>3</a>\u001b[0m params\u001b[39m=\u001b[39m{\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m100\u001b[39m,\u001b[39m500\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m0.05\u001b[39m,\u001b[39m0.1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=5'>6</a>\u001b[0m }\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=7'>8</a>\u001b[0m grid_cv\u001b[39m=\u001b[39mGridSearchCV(gb_clf,param_grid\u001b[39m=\u001b[39mparams , cv\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=8'>9</a>\u001b[0m grid_cv\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/boosting.ipynb#ch0000004?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m최적 하이퍼 파리미터: /n\u001b[39m\u001b[39m'\u001b[39m,grid_cv\u001b[39m.\u001b[39mbest_params_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gb_clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={\n",
    "    'n_estimators':[100,500],\n",
    "    'learning_rate':[0.05,0.1]\n",
    "}\n",
    "\n",
    "grid_cv=GridSearchCV(gb_clf,param_grid=params , cv=2, verbose=1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print('최적 하이퍼 파리미터: /n',grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4ba335b1acc55db6b97d63129af6fbe6175843e0be64b2659003ca573354abf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
