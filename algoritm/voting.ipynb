{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.DataFrame(cancer.data,columns=cancer.feature_names)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도 0.9474\n",
      "LogisticRegression 정확도: 0.9386\n",
      "KNeighborsClassifier 정확도: 0.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jangd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jangd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#개별 모델은 로지스틱 휘귀외 KNN임.\n",
    "lr_clf=LogisticRegression()\n",
    "knn_clf=KNeighborsClassifier(n_neighbors=8)\n",
    "vo_clf= VotingClassifier(estimators=[('LR',lr_clf),('KNN',knn_clf)], voting='soft')\n",
    "\n",
    "#개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기\n",
    "X_train,X_test, y_train, y_test = train_test_split(cancer.data,cancer.target, test_size=0.2,random_state=156)\n",
    "\n",
    "#VotingClassifier 학습/예측/평가\n",
    "vo_clf.fit(X_train,y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도 {0:.4f}'.format(accuracy_score(y_test,pred)))\n",
    "\n",
    "#개별 모델의 학습/예측/평가\n",
    "\n",
    "classifiers= [lr_clf,knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred=classifier.predict(X_test)\n",
    "    class_name=classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name,accuracy_score(y_test,pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df=pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),columns=['dup_cnt'])\n",
    "    feature_dup_df= feature_dup_df.reset_index()\n",
    "    new_feature_name_df=pd.merge(old_feature_name_df.reset_index(),feature_dup_df,how='outer')\n",
    "    new_feature_name_df['column_name']=new_feature_name_df[['column_name','dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1])\n",
    "                                                                                            if x[1]>0 else x[0], axis=1)\n",
    "    new_feature_name_df=new_feature_name_df.drop(['index'],axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "# cumcount는 몇번 나왔는지 누적횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_human_dataset():\n",
    "    #각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df=pd.read_csv('./data_sets/human_activity/features.txt',sep='\\s+', header=None, names=['column_index','column_name'])\n",
    "    \n",
    "    #중복된 피처명을 수정하는 get_new_feature_name_df() 를 이용, 신규 피처명 DataFrame생성\n",
    "    new_feature_name_df= get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    #DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:,1].values.tolist()\n",
    "    \n",
    "    #학습 피처데이터 셋과 테스트 피처 데이터를 DataFrame으로 로딩. 컬럼명은 feature_name적용\n",
    "    \n",
    "    X_train=pd.read_csv('./data_sets/human_activity/X_train.txt',sep='\\s+',names=feature_name)\n",
    "    X_test=pd.read_csv('./data_sets/human_activity/X_test.txt',sep='\\s+',names=feature_name)\n",
    "    \n",
    "    #학습 레이블과 테스트 레이블 데이터를 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train=pd.read_csv('./data_sets/human_activity/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test=pd.read_csv('./data_sets/human_activity/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    \n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "X_train,X_test, y_train, y_test =get_human_dataset()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df=pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                columns=['dup_cnt'])\n",
    "    \n",
    "    feature_dup_df= feature_dup_df.reset_index()\n",
    "    new_feature_name_df=pd.merge(old_feature_name_df.reset_index(),feature_dup_df,how='outer')\n",
    "    new_feature_name_df['column_name']=new_feature_name_df[['column_name','dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1])\n",
    "                                                                                            if x[1]>0 else x[0], axis=1)\n",
    "    new_feature_name_df=new_feature_name_df.drop(['index'],axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "# cumcount는 몇번 나왔는지 누적횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 학습 피처 데이터셋 info()\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7352 entries, 0 to 7351\n",
      "Columns: 561 entries, tBodyAcc-mean()-X to angle(Z,gravityMean)\n",
      "dtypes: float64(561)\n",
      "memory usage: 31.5 MB\n",
      "None\n",
      "6    1407\n",
      "5    1374\n",
      "4    1286\n",
      "1    1226\n",
      "2    1073\n",
      "3     986\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('## 학습 피처 데이터셋 info()')\n",
    "print(X_train.info())\n",
    "print(y_train['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 트리 예측 정확도: 0.8548\n",
      "DecisionTreeClassifier 기본 하이퍼 파라미터:\n",
      " {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 156, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 예제 반복 시 마다 동일한 예측 결과 도출을 위해 random_state 설정\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('결정 트리 예측 정확도: {0:.4f}'.format(accuracy))\n",
    "\n",
    "# DecisionTreeClassifier의 하이퍼 파라미터 추출\n",
    "print('DecisionTreeClassifier 기본 하이퍼 파라미터:\\n', dt_clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\voting.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39m# GridSearchCV객체의 cv_results_ 속성을 DataFrame으로 생성. \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=1'>2</a>\u001b[0m cv_results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(grid_cv\u001b[39m.\u001b[39;49mcv_results_)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=3'>4</a>\u001b[0m \u001b[39m# max_depth 파라미터 값과 그때의 테스트(Evaluation)셋, 학습 데이터 셋의 정확도 수치 추출\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=4'>5</a>\u001b[0m \u001b[39m# 사이킷런 버전이 업그레이드 되면서 아래의 GridSearchCV 객체의 cv_results_에서 mean_train_score는 더이상 제공되지 않습니다\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=5'>6</a>\u001b[0m \u001b[39m# cv_results_df[['param_max_depth', 'mean_test_score', 'mean_train_score']]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=6'>7</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=7'>8</a>\u001b[0m \u001b[39m# max_depth 파라미터 값과 그때의 테스트(Evaluation)셋, 학습 데이터 셋의 정확도 수치 추출\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000014?line=8'>9</a>\u001b[0m cv_results_df[[\u001b[39m'\u001b[39m\u001b[39mparam_max_depth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "# GridSearchCV객체의 cv_results_ 속성을 DataFrame으로 생성. \n",
    "cv_results_df = pd.DataFrame(grid_cv.cv_results_)\n",
    "\n",
    "# max_depth 파라미터 값과 그때의 테스트(Evaluation)셋, 학습 데이터 셋의 정확도 수치 추출\n",
    "# 사이킷런 버전이 업그레이드 되면서 아래의 GridSearchCV 객체의 cv_results_에서 mean_train_score는 더이상 제공되지 않습니다\n",
    "# cv_results_df[['param_max_depth', 'mean_test_score', 'mean_train_score']]\n",
    "\n",
    "# max_depth 파라미터 값과 그때의 테스트(Evaluation)셋, 학습 데이터 셋의 정확도 수치 추출\n",
    "cv_results_df[['param_max_depth', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_human_dataset():\n",
    "    #각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df=pd.read_csv('./data_sets/human_activity/features.txt',sep='\\s+', header=None, names=['column_index','column_name'])\n",
    "    \n",
    "    #중복된 피처명을 수정하는 get_new_feature_name_df() 를 이용, 신규 피처명 DataFrame생성\n",
    "    new_feature_name_df= get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    #DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:,1].values.tolist()\n",
    "    \n",
    "    #학습 피처데이터 셋과 테스트 피처 데이터를 DataFrame으로 로딩. 컬럼명은 feature_name적용\n",
    "    \n",
    "    X_train=pd.read_csv('./data_sets//human_activity/X_train.txt',sep='\\s+',names=feature_name)\n",
    "    X_test=pd.read_csv('./data_sets//human_activity/X_test.txt',sep='\\s+',names=feature_name)\n",
    "    \n",
    "    #학습 레이블과 테스트 레이블 데이터를 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train=pd.read_csv('./data_sets//human_activity/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test=pd.read_csv('./data_sets//human_activity/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    #로드된 학습/테스트용 DataFrame을 모두 반환\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "X_train,X_test, y_train, y_test =get_human_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\apps\\ml\\voting.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000009?line=11'>12</a>\u001b[0m rf_clf\u001b[39m=\u001b[39mRandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000009?line=12'>13</a>\u001b[0m grid_cv\u001b[39m=\u001b[39mGridSearchCV(rf_clf,param_grid\u001b[39m=\u001b[39mparams,cv\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000009?line=13'>14</a>\u001b[0m grid_csv\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000009?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m최적 하이퍼 파라미터 : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, gird_cv\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/apps/ml/voting.ipynb#ch0000009?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m최고 예측 정확도:\u001b[39m\u001b[39m{0:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(grid_cv\u001b[39m.\u001b[39mbest_score_))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_csv' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params={\n",
    "    'n_estimators':[100],\n",
    "    'max_depth':[6,8,10,12],\n",
    "    'min_samples_leaf':[8,12,18],\n",
    "    'min_samples_split':[8,16,20]\n",
    "}\n",
    "#RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf=RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "grid_cv=GridSearchCV(rf_clf,param_grid=params,cv=2,n_jobs=-1)\n",
    "grid_csv.fit(X_train,y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터 : \\n', gird_cv.best_params_)\n",
    "print('최고 예측 정확도:{0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4ba335b1acc55db6b97d63129af6fbe6175843e0be64b2659003ca573354abf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
